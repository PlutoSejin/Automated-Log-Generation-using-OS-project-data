{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZI4y3uSfPNe"
      },
      "outputs": [],
      "source": [
        "# 실행하고 링크 누르기\n",
        "# 런타임 유형 v2-8 TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs0QOp8f_UJo",
        "outputId": "e5d78f31-1e1c-4889-a3d8-759eb6f8d451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up GCS access...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Setting up GCS access...\")\n",
        "from google.colab import auth\n",
        "os.environ['USE_AUTH_EPHEM'] = '0'\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1E14d3plvEy"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTPCUM0itLIb",
        "outputId": "27a27189-d41d-4161-e2ad-eac8902e3ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n"
          ]
        }
      ],
      "source": [
        "#버전은 언제든지 변경이 될 수 있음. 라이브러리 문제. 아래 cell에서 import 되지 않으면 맞는 버전 찾기\n",
        "from IPython.display import clear_output\n",
        "!pip install gcsfs\n",
        "!pip install https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/tensorflow/tf-2.15.0/tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
        "!pip install tensorflow\n",
        "!pip install t5\n",
        "#!pip install 'jax[tpu]==0.4.26' -f https://storage.googleapis.com/jax-releases/libtpu_releases.html -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
        "#!pip install jaxlib==0.4.26\n",
        "!pip install tensorflow-gcs-config==2.15.0\n",
        "!pip install -q tensorflow-text==2.15.0\n",
        "clear_output()\n",
        "print(\"Installing dependencies...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q6Xa8haSthTP"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import os\n",
        "import gin\n",
        "from contextlib import contextmanager\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import logging as py_logging\n",
        "#tf.app.flags.DEFINE_string ('f', '', '')\n",
        "\n",
        "import t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "fd5b44ae-b51f-440c-ef0d-829815b96be7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]\n",
            "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, -1561952162512122479), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8215740505360834502), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 17179869184, -894499189513088272), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8819508387627147617), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1827041777991735787), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 17179869184, -7492708170558476597), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 17179869184, -8482167491708540088), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 17179869184, -8509274907454267702), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 17179869184, 8492411661914451856), _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -1145303463793675121)]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_gcs_config\n",
        "import tensorflow.compat.v1 as tf\n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "\n",
        "\n",
        "try:\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')  # TPU detection\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    tf.config.experimental.list_logical_devices('TPU')\n",
        "    tf.config.experimental.list_physical_devices('TPU')\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "    s = tf.Session()\n",
        "    print(s.list_devices())\n",
        "    #with tf.device():\n",
        "    tensorflow_gcs_config.configure_gcs_from_colab_auth(tf.config.list_logical_devices('TPU')[2])\n",
        "except ValueError:\n",
        "    raise BaseException(\n",
        "        'ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!'\n",
        "    )\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "#LOGGING\n",
        "tf.get_logger().propagate = False\n",
        "py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivJO3i9rbr4a"
      },
      "source": [
        "# Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y1pS3VGLbwWQ"
      },
      "outputs": [],
      "source": [
        "task = \"masking\" #@param ['masking']\n",
        "scheduler = \"noam\" #@param ['noam']\n",
        "VOCAB_PREFIX = 'tokenizer' #@param {type: \"string\"}\n",
        "TOKENIZER_DIR = f\"gs://log_gen/tokenizer/tokens/\"\n",
        "path_pretraining_task1 = f\"gs://log_gen/pretraining/{task}/pretraining.tsv\" #기존 LEONID 데이터셋\n",
        "path_word_pretraining_task = f\"gs://log_gen/pretraining/custom/word/no_dup_masked_methods.tsv\" # word 기준으로 나눈 데이터셋\n",
        "path_token_pretraining_task = f\"gs://log_gen/pretraining/custom/token/no_dup_masked_methods_with_token.tsv\" # token 기준으로 나눈 데이터셋\n",
        "# Storage paths\n",
        "PRETRAIN_MODEL_DIR = f\"gs://log_gen/pretrained-model/{task}\" # LEONID 데이터셋의 모델 위치\n",
        "PRETRAIN_MODEL_TOKEN_DIR = f\"gs://log_gen/pretrained-model/custom/token_real\" #token 기준으로 나눈 데이터셋의 모델 위치\n",
        "PRETRAIN_MODEL_WORD_DIR= f\"gs://log_gen/pretrained-model/custom/word_real\" #word 기준으로 나눈 데이터셋의 모델 위치\n",
        "\n",
        "#PRETRAIN_MODEL_DIR - path_pretraining_task1 쌍\n",
        "#PRETRAIN_MODEL_TOKEN_DIR - path_token_pretraining_task 쌍\n",
        "#PRETRAIN_MODEL_WORD_DIR - path_word_pretraining_task 쌍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53egC7agoZ9n"
      },
      "source": [
        "# Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WyI3CXuOpbX2"
      },
      "outputs": [],
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "\n",
        "vocab_model_path = os.path.join(TOKENIZER_DIR, f'{VOCAB_PREFIX}.model')\n",
        "vocab_path = os.path.join(TOKENIZER_DIR, f'{VOCAB_PREFIX}.vocab')\n",
        "\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "num_special_mask_tokens = 100 #@param {type: \"integer\"}\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, num_special_mask_tokens)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "glLJUm1dxIiH"
      },
      "outputs": [],
      "source": [
        "#Skip this cell for running the pre-training on the second task only\n",
        "nq_tsv_path = {\n",
        "    \"train\":      #path_pretraining_task1, #12671475\n",
        "                  #path_word_pretraining_task,#21820261\n",
        "                  path_token_pretraining_task #21923714\n",
        "} # 여기서 데이터셋 파일 위치 결정\n",
        "\n",
        "num_nq_examples_task1 = dict(train=21923714) # 데이터셋 파일에 따라 개수 바꾸기, 위에 있는 train에 파일에 따라 개수 적어놓음\n",
        "\n",
        "def load_dataset(split, shuffle_files=True):\n",
        "  del shuffle_files\n",
        "\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW3ofkihckPl"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf5jGnbqIFrn",
        "outputId": "191503bd-9927-4e8a-d351-7dfa81f9a990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'\"public static List<<extra_id_0> netSocketAddress> getAddresses(String s<extra_id_1> { <extra_id_2> (s == null) { throw new NullPoint<extra_id_3> Exception(\"\"Null host list\"\"); } if (s<extra_id_4><extra_id_5><extra_id_6> ().<extra_id_7> qual<extra_id_8> (<extra_id_9> \"\")) { throw new Il<extra_id_10> Arg<extra_id_11><extra_id_12> Exception(<extra_id_13><extra_id_14> hosts in list: ``<extra_id_15><extra_id_16> s<extra_id_17> \"\"\\'\\'\"\"); } ArrayList<InetSocketAddress> addrs = new ArrayList<InetSo<extra_id_18><extra_id_19> Address>();<extra_id_20> (String hoststuff <extra_id_21> <extra_id_22> .split(\"\"<extra_id_23> ?:\\\\\\\\s|,)+\"\")<extra_id_24> { if (hosts<extra_id_25> uff.equals<extra_id_26> \"\"\"\"))<extra_id_27> { continue; } int<extra_id_28> Colon = hoststuff.lastIndex<extra_id_29><extra_id_30> (\\'<extra_id_31> \\'); if (<extra_id_32> Colon < 1) { throw new Illegal<extra_id_33> umentException(\"\"In<extra_id_34> server ``\"\" +<extra_id_35> tuff<extra_id_36> \"\"<extra_id_37> \\' in list: \"\" + s); }<extra_id_38> host<extra_id_39> = hoststuff.sub<extra_id_40> (0, finalColon); String portNum<extra_id_41><extra_id_42> tuff<extra_id_43> substring(finalColon<extra_id_44> 1); add<extra_id_45> s.add<extra_id_46> new InetSocketAddress<extra_id_47><extra_id_48> Part, Integer.parseInt(portNum<extra_id_49> )); } assert !addrs.isEmpt<extra_id_50> () : \"\"No addrs found\"\"; return<extra_id_51>rs; }\"', 'output': b'\"<extra_id_0> I <extra_id_1> ) <extra_id_2> if <extra_id_3> er <extra_id_4> . <extra_id_5> t <extra_id_6> rim <extra_id_7> e <extra_id_8> s <extra_id_9> \"\" <extra_id_10> legal <extra_id_11> u <extra_id_12> ment <extra_id_13> \"\" <extra_id_14> No <extra_id_15> \"\" <extra_id_16>  + <extra_id_17>  + <extra_id_18> cke <extra_id_19> t <extra_id_20>  for <extra_id_21> : <extra_id_22> s <extra_id_23> ( <extra_id_24> ) <extra_id_25> t <extra_id_26> ( <extra_id_27>   <extra_id_28>  final <extra_id_29> O <extra_id_30> f <extra_id_31> : <extra_id_32> final <extra_id_33> Arg <extra_id_34> valid <extra_id_35>  hosts <extra_id_36>  + <extra_id_37> \\' <extra_id_38>  String <extra_id_39> Part <extra_id_40> string <extra_id_41>  = <extra_id_42>  hosts <extra_id_43> . <extra_id_44>  + <extra_id_45> r <extra_id_46> ( <extra_id_47> ( <extra_id_48> host <extra_id_49> ) <extra_id_50> y <extra_id_51>  add \"'}\n",
            "{'input': b'\"public static<extra_id_0><extra_id_1><extra_id_2><extra_id_3> SocketAddress> getAddresses(List<String> servers) { ArrayList<extra_id_4> InetSocketAddress> addrs = new ArrayList<InetSocketAddress>(servers<extra_id_5> size<extra_id_6> );<extra_id_7><extra_id_8> String server <extra_id_9> servers) { int finalCol<extra_id_10> = server.lastIndexOf(<extra_id_11> :\\'); if (finalColon < 1) { throw new IllegalArgumentException<extra_id_12> \"\"In<extra_id_13> server ``\"\" + server + \"\"\\'\\' in list: \"\" + server<extra_id_14> <extra_id_15> String hostPart = server.substring(0,<extra_id_16> Colon); String portNum = server.substring(final<extra_id_17> on + 1); add<extra_id_18> s.add(new<extra_id_19> netSo<extra_id_20> tAddress(<extra_id_21> Part, Integer.parse<extra_id_22> t(portNum))); }<extra_id_23><extra_id_24><extra_id_25><extra_id_26> rs<extra_id_27> isEmpty()<extra_id_28> { //<extra_id_29><extra_id_30> passed in empty, and shouldn\\'<extra_id_31><extra_id_32><extra_id_33> throw new<extra_id_34> legalArgumentException(<extra_id_35> servers cannot<extra_id_36> empty\"\"<extra_id_37>} return addrs; }\"', 'output': b'\"<extra_id_0>  List <extra_id_1> < <extra_id_2> I <extra_id_3> net <extra_id_4> < <extra_id_5> . <extra_id_6> () <extra_id_7>  for <extra_id_8>  ( <extra_id_9> : <extra_id_10> on <extra_id_11> \\' <extra_id_12> ( <extra_id_13> valid <extra_id_14> ); <extra_id_15> } <extra_id_16>  final <extra_id_17> Col <extra_id_18> r <extra_id_19>  I <extra_id_20> cke <extra_id_21> host <extra_id_22> In <extra_id_23>   <extra_id_24> if <extra_id_25>  ( <extra_id_26> add <extra_id_27> . <extra_id_28> ) <extra_id_29>  servers <extra_id_30>  was <extra_id_31> t <extra_id_32>  have <extra_id_33>  been <extra_id_34>  Il <extra_id_35> \"\" <extra_id_36>  be <extra_id_37> ); \"'}\n",
            "{'input': b'public static List<extra_id_0> InetSocketAddress> getAddressesFromURL(List<extra_id_1> URL<extra_id_2> servers) { <extra_id_3><extra_id_4> <<extra_id_5> netSocketAddress><extra_id_6> rs = new<extra_id_7><extra_id_8> List<InetSocketAddress>(servers.size<extra_id_9> ); for (<extra_id_10> server : servers) {<extra_id_11> rs.add(new InetSo<extra_id_12><extra_id_13> Address(server.getHost<extra_id_14> , server.<extra_id_15>Port())); } return addrs; }', 'output': b'<extra_id_0> < <extra_id_1> < <extra_id_2> > <extra_id_3> Array <extra_id_4> List <extra_id_5> I <extra_id_6>  add <extra_id_7>   <extra_id_8> Array <extra_id_9> () <extra_id_10> URL <extra_id_11>  add <extra_id_12> cke <extra_id_13> t <extra_id_14> () <extra_id_15> get '}\n",
            "{'input': b'\"public NodeIterator(<extra_id_0> t key<extra_id_1> t) { start<extra_id_2> keyStart; next = start; compute<extra_id_3><extra_id_4> ; assert next ><extra_id_5> 0 || nodes.length == 1 : \"\"Starting sequence at \"\" + start +<extra_id_6><extra_id_7> \"\" + nodes.length +<extra_id_8> next is \"\" + next<extra_id_9>}\"', 'output': b'\"<extra_id_0> in <extra_id_1> Star <extra_id_2>  = <extra_id_3> Next <extra_id_4> () <extra_id_5> = <extra_id_6>  \"\" <extra_id_7>  of <extra_id_8>  \"\" <extra_id_9> ; \"'}\n",
            "{'input': b'private void computeNext() {<extra_id_0> if<extra_id_1> ++n<extra_id_2> >= no<extra_id_3> .length) <extra_id_4> next = 0; } if<extra_id_5> next<extra_id_6>= start) { next = -1; } }', 'output': b'<extra_id_0>   <extra_id_1>  ( <extra_id_2> ext <extra_id_3> des <extra_id_4> { <extra_id_5>  ( <extra_id_6>  = '}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(load_dataset(\"train\").take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I59E58_cmEI",
        "outputId": "28e033f2-6c57-406e-88c8-27990cb802fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few raw train examples...\n",
            "{'input': b'\"public static List<<extra_id_0> netSocketAddress> getAddresses(String s<extra_id_1> { <extra_id_2> (s == null) { throw new NullPoint<extra_id_3> Exception(\"\"Null host list\"\"); } if (s<extra_id_4><extra_id_5><extra_id_6> ().<extra_id_7> qual<extra_id_8> (<extra_id_9> \"\")) { throw new Il<extra_id_10> Arg<extra_id_11><extra_id_12> Exception(<extra_id_13><extra_id_14> hosts in list: ``<extra_id_15><extra_id_16> s<extra_id_17> \"\"\\'\\'\"\"); } ArrayList<InetSocketAddress> addrs = new ArrayList<InetSo<extra_id_18><extra_id_19> Address>();<extra_id_20> (String hoststuff <extra_id_21> <extra_id_22> .split(\"\"<extra_id_23> ?:\\\\\\\\s|,)+\"\")<extra_id_24> { if (hosts<extra_id_25> uff.equals<extra_id_26> \"\"\"\"))<extra_id_27> { continue; } int<extra_id_28> Colon = hoststuff.lastIndex<extra_id_29><extra_id_30> (\\'<extra_id_31> \\'); if (<extra_id_32> Colon < 1) { throw new Illegal<extra_id_33> umentException(\"\"In<extra_id_34> server ``\"\" +<extra_id_35> tuff<extra_id_36> \"\"<extra_id_37> \\' in list: \"\" + s); }<extra_id_38> host<extra_id_39> = hoststuff.sub<extra_id_40> (0, finalColon); String portNum<extra_id_41><extra_id_42> tuff<extra_id_43> substring(finalColon<extra_id_44> 1); add<extra_id_45> s.add<extra_id_46> new InetSocketAddress<extra_id_47><extra_id_48> Part, Integer.parseInt(portNum<extra_id_49> )); } assert !addrs.isEmpt<extra_id_50> () : \"\"No addrs found\"\"; return<extra_id_51>rs; }\"', 'output': b'\"<extra_id_0> I <extra_id_1> ) <extra_id_2> if <extra_id_3> er <extra_id_4> . <extra_id_5> t <extra_id_6> rim <extra_id_7> e <extra_id_8> s <extra_id_9> \"\" <extra_id_10> legal <extra_id_11> u <extra_id_12> ment <extra_id_13> \"\" <extra_id_14> No <extra_id_15> \"\" <extra_id_16>  + <extra_id_17>  + <extra_id_18> cke <extra_id_19> t <extra_id_20>  for <extra_id_21> : <extra_id_22> s <extra_id_23> ( <extra_id_24> ) <extra_id_25> t <extra_id_26> ( <extra_id_27>   <extra_id_28>  final <extra_id_29> O <extra_id_30> f <extra_id_31> : <extra_id_32> final <extra_id_33> Arg <extra_id_34> valid <extra_id_35>  hosts <extra_id_36>  + <extra_id_37> \\' <extra_id_38>  String <extra_id_39> Part <extra_id_40> string <extra_id_41>  = <extra_id_42>  hosts <extra_id_43> . <extra_id_44>  + <extra_id_45> r <extra_id_46> ( <extra_id_47> ( <extra_id_48> host <extra_id_49> ) <extra_id_50> y <extra_id_51>  add \"'}\n",
            "{'input': b'\"public static<extra_id_0><extra_id_1><extra_id_2><extra_id_3> SocketAddress> getAddresses(List<String> servers) { ArrayList<extra_id_4> InetSocketAddress> addrs = new ArrayList<InetSocketAddress>(servers<extra_id_5> size<extra_id_6> );<extra_id_7><extra_id_8> String server <extra_id_9> servers) { int finalCol<extra_id_10> = server.lastIndexOf(<extra_id_11> :\\'); if (finalColon < 1) { throw new IllegalArgumentException<extra_id_12> \"\"In<extra_id_13> server ``\"\" + server + \"\"\\'\\' in list: \"\" + server<extra_id_14> <extra_id_15> String hostPart = server.substring(0,<extra_id_16> Colon); String portNum = server.substring(final<extra_id_17> on + 1); add<extra_id_18> s.add(new<extra_id_19> netSo<extra_id_20> tAddress(<extra_id_21> Part, Integer.parse<extra_id_22> t(portNum))); }<extra_id_23><extra_id_24><extra_id_25><extra_id_26> rs<extra_id_27> isEmpty()<extra_id_28> { //<extra_id_29><extra_id_30> passed in empty, and shouldn\\'<extra_id_31><extra_id_32><extra_id_33> throw new<extra_id_34> legalArgumentException(<extra_id_35> servers cannot<extra_id_36> empty\"\"<extra_id_37>} return addrs; }\"', 'output': b'\"<extra_id_0>  List <extra_id_1> < <extra_id_2> I <extra_id_3> net <extra_id_4> < <extra_id_5> . <extra_id_6> () <extra_id_7>  for <extra_id_8>  ( <extra_id_9> : <extra_id_10> on <extra_id_11> \\' <extra_id_12> ( <extra_id_13> valid <extra_id_14> ); <extra_id_15> } <extra_id_16>  final <extra_id_17> Col <extra_id_18> r <extra_id_19>  I <extra_id_20> cke <extra_id_21> host <extra_id_22> In <extra_id_23>   <extra_id_24> if <extra_id_25>  ( <extra_id_26> add <extra_id_27> . <extra_id_28> ) <extra_id_29>  servers <extra_id_30>  was <extra_id_31> t <extra_id_32>  have <extra_id_33>  been <extra_id_34>  Il <extra_id_35> \"\" <extra_id_36>  be <extra_id_37> ); \"'}\n",
            "{'input': b'public static List<extra_id_0> InetSocketAddress> getAddressesFromURL(List<extra_id_1> URL<extra_id_2> servers) { <extra_id_3><extra_id_4> <<extra_id_5> netSocketAddress><extra_id_6> rs = new<extra_id_7><extra_id_8> List<InetSocketAddress>(servers.size<extra_id_9> ); for (<extra_id_10> server : servers) {<extra_id_11> rs.add(new InetSo<extra_id_12><extra_id_13> Address(server.getHost<extra_id_14> , server.<extra_id_15>Port())); } return addrs; }', 'output': b'<extra_id_0> < <extra_id_1> < <extra_id_2> > <extra_id_3> Array <extra_id_4> List <extra_id_5> I <extra_id_6>  add <extra_id_7>   <extra_id_8> Array <extra_id_9> () <extra_id_10> URL <extra_id_11>  add <extra_id_12> cke <extra_id_13> t <extra_id_14> () <extra_id_15> get '}\n",
            "{'input': b'\"public NodeIterator(<extra_id_0> t key<extra_id_1> t) { start<extra_id_2> keyStart; next = start; compute<extra_id_3><extra_id_4> ; assert next ><extra_id_5> 0 || nodes.length == 1 : \"\"Starting sequence at \"\" + start +<extra_id_6><extra_id_7> \"\" + nodes.length +<extra_id_8> next is \"\" + next<extra_id_9>}\"', 'output': b'\"<extra_id_0> in <extra_id_1> Star <extra_id_2>  = <extra_id_3> Next <extra_id_4> () <extra_id_5> = <extra_id_6>  \"\" <extra_id_7>  of <extra_id_8>  \"\" <extra_id_9> ; \"'}\n",
            "{'input': b'private void computeNext() {<extra_id_0> if<extra_id_1> ++n<extra_id_2> >= no<extra_id_3> .length) <extra_id_4> next = 0; } if<extra_id_5> next<extra_id_6>= start) { next = -1; } }', 'output': b'<extra_id_0>   <extra_id_1>  ( <extra_id_2> ext <extra_id_3> des <extra_id_4> { <extra_id_5>  ( <extra_id_6>  = '}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(load_dataset(\"train\").take(5)):\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t43IonWQ5OHi"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RENUHKu75KXw"
      },
      "outputs": [],
      "source": [
        "def preprocessing(ds):\n",
        "\n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join(['MASKING: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09QxYschc-vt"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efhmaHs6aqtm",
        "outputId": "f471abe8-b816-48b6-a761-86134056abde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few preprocessed train examples...\n",
            "{'inputs': b'MASKING: \"public static List<<extra_id_0> netSocketAddress> getAddresses(String s<extra_id_1> { <extra_id_2> (s == null) { throw new NullPoint<extra_id_3> Exception(\"\"Null host list\"\"); } if (s<extra_id_4><extra_id_5><extra_id_6> ().<extra_id_7> qual<extra_id_8> (<extra_id_9> \"\")) { throw new Il<extra_id_10> Arg<extra_id_11><extra_id_12> Exception(<extra_id_13><extra_id_14> hosts in list: ``<extra_id_15><extra_id_16> s<extra_id_17> \"\"\\'\\'\"\"); } ArrayList<InetSocketAddress> addrs = new ArrayList<InetSo<extra_id_18><extra_id_19> Address>();<extra_id_20> (String hoststuff <extra_id_21> <extra_id_22> .split(\"\"<extra_id_23> ?:\\\\\\\\s|,)+\"\")<extra_id_24> { if (hosts<extra_id_25> uff.equals<extra_id_26> \"\"\"\"))<extra_id_27> { continue; } int<extra_id_28> Colon = hoststuff.lastIndex<extra_id_29><extra_id_30> (\\'<extra_id_31> \\'); if (<extra_id_32> Colon < 1) { throw new Illegal<extra_id_33> umentException(\"\"In<extra_id_34> server ``\"\" +<extra_id_35> tuff<extra_id_36> \"\"<extra_id_37> \\' in list: \"\" + s); }<extra_id_38> host<extra_id_39> = hoststuff.sub<extra_id_40> (0, finalColon); String portNum<extra_id_41><extra_id_42> tuff<extra_id_43> substring(finalColon<extra_id_44> 1); add<extra_id_45> s.add<extra_id_46> new InetSocketAddress<extra_id_47><extra_id_48> Part, Integer.parseInt(portNum<extra_id_49> )); } assert !addrs.isEmpt<extra_id_50> () : \"\"No addrs found\"\"; return<extra_id_51>rs; }\"', 'targets': b'\"<extra_id_0> I <extra_id_1> ) <extra_id_2> if <extra_id_3> er <extra_id_4> . <extra_id_5> t <extra_id_6> rim <extra_id_7> e <extra_id_8> s <extra_id_9> \"\" <extra_id_10> legal <extra_id_11> u <extra_id_12> ment <extra_id_13> \"\" <extra_id_14> No <extra_id_15> \"\" <extra_id_16>  + <extra_id_17>  + <extra_id_18> cke <extra_id_19> t <extra_id_20>  for <extra_id_21> : <extra_id_22> s <extra_id_23> ( <extra_id_24> ) <extra_id_25> t <extra_id_26> ( <extra_id_27>   <extra_id_28>  final <extra_id_29> O <extra_id_30> f <extra_id_31> : <extra_id_32> final <extra_id_33> Arg <extra_id_34> valid <extra_id_35>  hosts <extra_id_36>  + <extra_id_37> \\' <extra_id_38>  String <extra_id_39> Part <extra_id_40> string <extra_id_41>  = <extra_id_42>  hosts <extra_id_43> . <extra_id_44>  + <extra_id_45> r <extra_id_46> ( <extra_id_47> ( <extra_id_48> host <extra_id_49> ) <extra_id_50> y <extra_id_51>  add \"'}\n",
            "{'inputs': b'MASKING: \"public static<extra_id_0><extra_id_1><extra_id_2><extra_id_3> SocketAddress> getAddresses(List<String> servers) { ArrayList<extra_id_4> InetSocketAddress> addrs = new ArrayList<InetSocketAddress>(servers<extra_id_5> size<extra_id_6> );<extra_id_7><extra_id_8> String server <extra_id_9> servers) { int finalCol<extra_id_10> = server.lastIndexOf(<extra_id_11> :\\'); if (finalColon < 1) { throw new IllegalArgumentException<extra_id_12> \"\"In<extra_id_13> server ``\"\" + server + \"\"\\'\\' in list: \"\" + server<extra_id_14> <extra_id_15> String hostPart = server.substring(0,<extra_id_16> Colon); String portNum = server.substring(final<extra_id_17> on + 1); add<extra_id_18> s.add(new<extra_id_19> netSo<extra_id_20> tAddress(<extra_id_21> Part, Integer.parse<extra_id_22> t(portNum))); }<extra_id_23><extra_id_24><extra_id_25><extra_id_26> rs<extra_id_27> isEmpty()<extra_id_28> { //<extra_id_29><extra_id_30> passed in empty, and shouldn\\'<extra_id_31><extra_id_32><extra_id_33> throw new<extra_id_34> legalArgumentException(<extra_id_35> servers cannot<extra_id_36> empty\"\"<extra_id_37>} return addrs; }\"', 'targets': b'\"<extra_id_0>  List <extra_id_1> < <extra_id_2> I <extra_id_3> net <extra_id_4> < <extra_id_5> . <extra_id_6> () <extra_id_7>  for <extra_id_8>  ( <extra_id_9> : <extra_id_10> on <extra_id_11> \\' <extra_id_12> ( <extra_id_13> valid <extra_id_14> ); <extra_id_15> } <extra_id_16>  final <extra_id_17> Col <extra_id_18> r <extra_id_19>  I <extra_id_20> cke <extra_id_21> host <extra_id_22> In <extra_id_23>   <extra_id_24> if <extra_id_25>  ( <extra_id_26> add <extra_id_27> . <extra_id_28> ) <extra_id_29>  servers <extra_id_30>  was <extra_id_31> t <extra_id_32>  have <extra_id_33>  been <extra_id_34>  Il <extra_id_35> \"\" <extra_id_36>  be <extra_id_37> ); \"'}\n",
            "{'inputs': b'MASKING: public static List<extra_id_0> InetSocketAddress> getAddressesFromURL(List<extra_id_1> URL<extra_id_2> servers) { <extra_id_3><extra_id_4> <<extra_id_5> netSocketAddress><extra_id_6> rs = new<extra_id_7><extra_id_8> List<InetSocketAddress>(servers.size<extra_id_9> ); for (<extra_id_10> server : servers) {<extra_id_11> rs.add(new InetSo<extra_id_12><extra_id_13> Address(server.getHost<extra_id_14> , server.<extra_id_15>Port())); } return addrs; }', 'targets': b'<extra_id_0> < <extra_id_1> < <extra_id_2> > <extra_id_3> Array <extra_id_4> List <extra_id_5> I <extra_id_6>  add <extra_id_7>   <extra_id_8> Array <extra_id_9> () <extra_id_10> URL <extra_id_11>  add <extra_id_12> cke <extra_id_13> t <extra_id_14> () <extra_id_15> get '}\n",
            "{'inputs': b'MASKING: \"public NodeIterator(<extra_id_0> t key<extra_id_1> t) { start<extra_id_2> keyStart; next = start; compute<extra_id_3><extra_id_4> ; assert next ><extra_id_5> 0 || nodes.length == 1 : \"\"Starting sequence at \"\" + start +<extra_id_6><extra_id_7> \"\" + nodes.length +<extra_id_8> next is \"\" + next<extra_id_9>}\"', 'targets': b'\"<extra_id_0> in <extra_id_1> Star <extra_id_2>  = <extra_id_3> Next <extra_id_4> () <extra_id_5> = <extra_id_6>  \"\" <extra_id_7>  of <extra_id_8>  \"\" <extra_id_9> ; \"'}\n",
            "{'inputs': b'MASKING: private void computeNext() {<extra_id_0> if<extra_id_1> ++n<extra_id_2> >= no<extra_id_3> .length) <extra_id_4> next = 0; } if<extra_id_5> next<extra_id_6>= start) { next = -1; } }', 'targets': b'<extra_id_0>   <extra_id_1>  ( <extra_id_2> ext <extra_id_3> des <extra_id_4> { <extra_id_5>  ( <extra_id_6>  = '}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few preprocessed train examples...\")\n",
        "sample = tfds.as_numpy(preprocessing(load_dataset(\"train\").take(5)))\n",
        "for ex in sample:\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku3C3gKC5IEx",
        "outputId": "a8245e98-432a-436d-8942-053708a5877a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A few preprocessed train examples...\n",
            "{'inputs': b'MASKING: \"public static List<<extra_id_0> netSocketAddress> getAddresses(String s<extra_id_1> { <extra_id_2> (s == null) { throw new NullPoint<extra_id_3> Exception(\"\"Null host list\"\"); } if (s<extra_id_4><extra_id_5><extra_id_6> ().<extra_id_7> qual<extra_id_8> (<extra_id_9> \"\")) { throw new Il<extra_id_10> Arg<extra_id_11><extra_id_12> Exception(<extra_id_13><extra_id_14> hosts in list: ``<extra_id_15><extra_id_16> s<extra_id_17> \"\"\\'\\'\"\"); } ArrayList<InetSocketAddress> addrs = new ArrayList<InetSo<extra_id_18><extra_id_19> Address>();<extra_id_20> (String hoststuff <extra_id_21> <extra_id_22> .split(\"\"<extra_id_23> ?:\\\\\\\\s|,)+\"\")<extra_id_24> { if (hosts<extra_id_25> uff.equals<extra_id_26> \"\"\"\"))<extra_id_27> { continue; } int<extra_id_28> Colon = hoststuff.lastIndex<extra_id_29><extra_id_30> (\\'<extra_id_31> \\'); if (<extra_id_32> Colon < 1) { throw new Illegal<extra_id_33> umentException(\"\"In<extra_id_34> server ``\"\" +<extra_id_35> tuff<extra_id_36> \"\"<extra_id_37> \\' in list: \"\" + s); }<extra_id_38> host<extra_id_39> = hoststuff.sub<extra_id_40> (0, finalColon); String portNum<extra_id_41><extra_id_42> tuff<extra_id_43> substring(finalColon<extra_id_44> 1); add<extra_id_45> s.add<extra_id_46> new InetSocketAddress<extra_id_47><extra_id_48> Part, Integer.parseInt(portNum<extra_id_49> )); } assert !addrs.isEmpt<extra_id_50> () : \"\"No addrs found\"\"; return<extra_id_51>rs; }\"', 'targets': b'\"<extra_id_0> I <extra_id_1> ) <extra_id_2> if <extra_id_3> er <extra_id_4> . <extra_id_5> t <extra_id_6> rim <extra_id_7> e <extra_id_8> s <extra_id_9> \"\" <extra_id_10> legal <extra_id_11> u <extra_id_12> ment <extra_id_13> \"\" <extra_id_14> No <extra_id_15> \"\" <extra_id_16>  + <extra_id_17>  + <extra_id_18> cke <extra_id_19> t <extra_id_20>  for <extra_id_21> : <extra_id_22> s <extra_id_23> ( <extra_id_24> ) <extra_id_25> t <extra_id_26> ( <extra_id_27>   <extra_id_28>  final <extra_id_29> O <extra_id_30> f <extra_id_31> : <extra_id_32> final <extra_id_33> Arg <extra_id_34> valid <extra_id_35>  hosts <extra_id_36>  + <extra_id_37> \\' <extra_id_38>  String <extra_id_39> Part <extra_id_40> string <extra_id_41>  = <extra_id_42>  hosts <extra_id_43> . <extra_id_44>  + <extra_id_45> r <extra_id_46> ( <extra_id_47> ( <extra_id_48> host <extra_id_49> ) <extra_id_50> y <extra_id_51>  add \"'}\n",
            "{'inputs': b'MASKING: \"public static<extra_id_0><extra_id_1><extra_id_2><extra_id_3> SocketAddress> getAddresses(List<String> servers) { ArrayList<extra_id_4> InetSocketAddress> addrs = new ArrayList<InetSocketAddress>(servers<extra_id_5> size<extra_id_6> );<extra_id_7><extra_id_8> String server <extra_id_9> servers) { int finalCol<extra_id_10> = server.lastIndexOf(<extra_id_11> :\\'); if (finalColon < 1) { throw new IllegalArgumentException<extra_id_12> \"\"In<extra_id_13> server ``\"\" + server + \"\"\\'\\' in list: \"\" + server<extra_id_14> <extra_id_15> String hostPart = server.substring(0,<extra_id_16> Colon); String portNum = server.substring(final<extra_id_17> on + 1); add<extra_id_18> s.add(new<extra_id_19> netSo<extra_id_20> tAddress(<extra_id_21> Part, Integer.parse<extra_id_22> t(portNum))); }<extra_id_23><extra_id_24><extra_id_25><extra_id_26> rs<extra_id_27> isEmpty()<extra_id_28> { //<extra_id_29><extra_id_30> passed in empty, and shouldn\\'<extra_id_31><extra_id_32><extra_id_33> throw new<extra_id_34> legalArgumentException(<extra_id_35> servers cannot<extra_id_36> empty\"\"<extra_id_37>} return addrs; }\"', 'targets': b'\"<extra_id_0>  List <extra_id_1> < <extra_id_2> I <extra_id_3> net <extra_id_4> < <extra_id_5> . <extra_id_6> () <extra_id_7>  for <extra_id_8>  ( <extra_id_9> : <extra_id_10> on <extra_id_11> \\' <extra_id_12> ( <extra_id_13> valid <extra_id_14> ); <extra_id_15> } <extra_id_16>  final <extra_id_17> Col <extra_id_18> r <extra_id_19>  I <extra_id_20> cke <extra_id_21> host <extra_id_22> In <extra_id_23>   <extra_id_24> if <extra_id_25>  ( <extra_id_26> add <extra_id_27> . <extra_id_28> ) <extra_id_29>  servers <extra_id_30>  was <extra_id_31> t <extra_id_32>  have <extra_id_33>  been <extra_id_34>  Il <extra_id_35> \"\" <extra_id_36>  be <extra_id_37> ); \"'}\n",
            "{'inputs': b'MASKING: public static List<extra_id_0> InetSocketAddress> getAddressesFromURL(List<extra_id_1> URL<extra_id_2> servers) { <extra_id_3><extra_id_4> <<extra_id_5> netSocketAddress><extra_id_6> rs = new<extra_id_7><extra_id_8> List<InetSocketAddress>(servers.size<extra_id_9> ); for (<extra_id_10> server : servers) {<extra_id_11> rs.add(new InetSo<extra_id_12><extra_id_13> Address(server.getHost<extra_id_14> , server.<extra_id_15>Port())); } return addrs; }', 'targets': b'<extra_id_0> < <extra_id_1> < <extra_id_2> > <extra_id_3> Array <extra_id_4> List <extra_id_5> I <extra_id_6>  add <extra_id_7>   <extra_id_8> Array <extra_id_9> () <extra_id_10> URL <extra_id_11>  add <extra_id_12> cke <extra_id_13> t <extra_id_14> () <extra_id_15> get '}\n",
            "{'inputs': b'MASKING: \"public NodeIterator(<extra_id_0> t key<extra_id_1> t) { start<extra_id_2> keyStart; next = start; compute<extra_id_3><extra_id_4> ; assert next ><extra_id_5> 0 || nodes.length == 1 : \"\"Starting sequence at \"\" + start +<extra_id_6><extra_id_7> \"\" + nodes.length +<extra_id_8> next is \"\" + next<extra_id_9>}\"', 'targets': b'\"<extra_id_0> in <extra_id_1> Star <extra_id_2>  = <extra_id_3> Next <extra_id_4> () <extra_id_5> = <extra_id_6>  \"\" <extra_id_7>  of <extra_id_8>  \"\" <extra_id_9> ; \"'}\n",
            "{'inputs': b'MASKING: private void computeNext() {<extra_id_0> if<extra_id_1> ++n<extra_id_2> >= no<extra_id_3> .length) <extra_id_4> next = 0; } if<extra_id_5> next<extra_id_6>= start) { next = -1; } }', 'targets': b'<extra_id_0>   <extra_id_1>  ( <extra_id_2> ext <extra_id_3> des <extra_id_4> { <extra_id_5>  ( <extra_id_6>  = '}\n"
          ]
        }
      ],
      "source": [
        "print(\"A few preprocessed train examples...\")\n",
        "sample = tfds.as_numpy(preprocessing(load_dataset(\"train\").take(5)))\n",
        "for ex in sample:\n",
        "  print(ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rij6ym_m5eJj"
      },
      "source": [
        "# Set up task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqCowItk5gsm",
        "outputId": "ee84e29f-8f19-455a-aa7f-2e7e1437021b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7c8ca90f4340>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t5.data.TaskRegistry.remove('masking')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"masking\",\n",
        "    dataset_fn=load_dataset,\n",
        "    splits=[\"train\"],\n",
        "    text_preprocessor=preprocessing,\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    num_input_examples=num_nq_examples_task1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHDGb3gFsoS6"
      },
      "source": [
        "## Mixture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDEHaEz9uP5z",
        "outputId": "ff34f96a-4547-408c-c47b-70c812cad416"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seqio.dataset_providers.Mixture at 0x7c8ca6fad840>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"pretraining\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"pretraining\",\n",
        "    [\"masking\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7C49Pd4u0DC"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "e7vdtJGspE1E",
        "outputId": "d0a0e42b-d8be-49d0-da58-f15d48a4cdbf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AttributeError                            Traceback (most recent call last)\\n<ipython-input-16-235c7bc08e88> in <cell line: 1>()\\n----> 1 from mesh_tensorflow.transformer.learning_rate_schedules import learning_rate_schedule_noam\\n      2 from t5 import models\\n      3 # Model properties\\n      4 MODEL_SIZE = \"small\"\\n      5 model_parallelism, train_batch_size, keep_checkpoint_max = {\\n\\n2 frames\\n/usr/local/lib/python3.10/dist-packages/mesh_tensorflow/tpu_variables.py in <module>\\n    224 \\n    225 \\n--> 226 ops.register_tensor_conversion_function(ReplicatedVariable, _tensor_conversion)\\n    227 \\n    228 if not TF_23:\\n\\nAttributeError: module \\'tensorflow.python.framework.ops\\' has no attribute \\'register_tensor_conversion_function\\''"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"AttributeError                            Traceback (most recent call last)\n",
        "<ipython-input-16-235c7bc08e88> in <cell line: 1>()\n",
        "----> 1 from mesh_tensorflow.transformer.learning_rate_schedules import learning_rate_schedule_noam\n",
        "      2 from t5 import models\n",
        "      3 # Model properties\n",
        "      4 MODEL_SIZE = \"small\"\n",
        "      5 model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "\n",
        "2 frames\n",
        "/usr/local/lib/python3.10/dist-packages/mesh_tensorflow/tpu_variables.py in <module>\n",
        "    224\n",
        "    225\n",
        "--> 226 ops.register_tensor_conversion_function(ReplicatedVariable, _tensor_conversion)\n",
        "    227\n",
        "    228 if not TF_23:\n",
        "\n",
        "AttributeError: module 'tensorflow.python.framework.ops' has no attribute 'register_tensor_conversion_function'\"\"\"\n",
        "#위와 같은 에러가 아래 cell에서 발생 가능\n",
        "\n",
        "# 에러에서 \"/usr/local/lib/python3.10/dist-packages/mesh_tensorflow/tpu_variables.py/usr/local/lib/python3.10/dist-packages/mesh_tensorflow/tpu_variables.py\"를 누르면 tpu_variable.py가 옆에 나옴\n",
        "# tpu_variable.py 226줄에서 \"ops.register_tensor_conversion_function(ReplicatedVariable, _tensor_conversion)\" 를\n",
        "# ops.tensor_conversion_registry.register_tensor_conversion_function(ReplicatedVariable, _tensor_conversion) 로 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_3Qx699vN302"
      },
      "outputs": [],
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import learning_rate_schedule_noam\n",
        "from t5 import models\n",
        "# Model properties\n",
        "MODEL_SIZE = \"small\"\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 128, 16), #change batch 128|\n",
        "    \"base\": (2, 16, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(PRETRAIN_MODEL_TOKEN_DIR)#PRETRAIN_MODEL_WORD_DIR)#PRETRAIN_MODEL_DIR)\n",
        "\n",
        "# Mesh Tensorflow Transformer\n",
        "model = models.mtf_model.MtfModel(\n",
        "    model_dir=PRETRAIN_MODEL_TOKEN_DIR, #PRETRAIN_MODEL_WORD_DIR,#PRETRAIN_MODEL_DIR,\n",
        "    tpu='local',\n",
        "    #tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = learning_rate_schedule_noam,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=10000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr1Vh37rPEpf",
        "outputId": "3cc27db3-a299-4f52-c4a3-1b6d6cc7bf95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETwijMTDvpZL"
      },
      "source": [
        "# Set up learning Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq7RegMMvuk5",
        "outputId": "624432a0-14f4-498c-f01a-aa44665449de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://log_gen/learning_rate_scheduler/noam/operative_config.gin...\n",
            "/ [1/1 files][ 12.4 KiB/ 12.4 KiB] 100% Done                                    \n",
            "Operation completed over 1 objects/12.4 KiB.                                     \n"
          ]
        }
      ],
      "source": [
        "remote_gin_path = f\"gs://log_gen/learning_rate_scheduler/{scheduler}/operative_config.gin\"\n",
        "local_gin_path = \"/content/operative_config.gin\"\n",
        "!gsutil -m cp $remote_gin_path $local_gin_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GmAo9yirFx1V"
      },
      "outputs": [],
      "source": [
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(local_gin_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekEBp20TvU91"
      },
      "source": [
        "# Pre-train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7PNnjdcmGr2",
        "outputId": "6b50e8d6-77fa-44d7-9f1e-34d2a9864821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming from checkpoint: gs://log_gen/pretrained-model/custom/token_real/model.ckpt-500000\n"
          ]
        }
      ],
      "source": [
        "#체크 포인트가 있으면 로드\n",
        "checkpoint_dir = PRETRAIN_MODEL_TOKEN_DIR\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "    print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Starting training from scratch.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtVMlRJJlnuj",
        "outputId": "a32a645b-d7e3-476c-94e8-f3eee71cf894"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "From /usr/local/lib/python3.10/dist-packages/mesh_tensorflow/transformer/utils.py:2043: TPUConfig.__new__ (from tensorflow_estimator.python.estimator.tpu.tpu_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/mesh_tensorflow/transformer/utils.py:2059: RunConfig.__init__ (from tensorflow_estimator.python.estimator.tpu.tpu_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_config.py:268: RunConfig.__init__ (from tensorflow_estimator.python.estimator.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/mesh_tensorflow/transformer/utils.py:2096: TPUEstimator.__init__ (from tensorflow_estimator.python.estimator.tpu.tpu_estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:2812: Estimator.__init__ (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:2372: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/basic_session_run_hooks.py:686: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "WARNING:absl:Using an uncached FunctionDataset for training is not recommended since it often results in insufficient shuffling on restarts, resulting in overfitting. It is highly recommended that you cache this task before training with it or use a data source that supports lower-level shuffling (e.g., FileDataSource).\n",
            "SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "From /usr/local/lib/python3.10/dist-packages/mesh_tensorflow/transformer/utils.py:999: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/mesh_tensorflow/transformer/utils.py:1014: TPUEstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.tpu.tpu_estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3329: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:3370: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1416: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1176: get_checkpoint_mtimes (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:761: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "TPU device does not support heartbeats. Failure handling will be disabled.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.keras instead.\n",
            "From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ],
      "source": [
        "#checkpoint 부터 다시 학습\n",
        "TRAIN_STEPS = 500000 #@param {type: \"integer\"}\n",
        "model.train(\"pretraining\", TRAIN_STEPS, init_checkpoint=latest_checkpoint) #pretraining = mixture name #checkpoint가 있다면\n",
        "#model.train(\"pretraining\", TRAIN_STEPS) #checkpoint가 없다면"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNoP8SbBJ92a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
